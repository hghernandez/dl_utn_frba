{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I -  Tensorflow & Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--O_kCr-s2--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/i/lkli02223oqhlac1jetz.png\" style=\"width:800px;\"/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo I: Regla XOR en Tensorflow c/ Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]  # XOR input\n",
    "output_data = [[1, 0], [0, 1], [0, 1], [1, 0]]  # XOR output\n",
    "\n",
    "output_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "#---------------------------------------------------------------------#\n",
    "input_layer = Input(shape=2)\n",
    "dense_0 = Dense(10, activation='relu') (input_layer)\n",
    "dense_1 = Dense(10, activation='relu') (dense_0)\n",
    "dense_2 = Dense(10, activation='relu') (dense_1)\n",
    "output_layer = Dense(output_classes, activation='softmax') (dense_2)\n",
    "#---------------------------------------------------------------------#\n",
    "model = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                30        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 272\n",
      "Trainable params: 272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adam_optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=adam_optimizer, loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 752ms/step - loss: 0.6938\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6854\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6772\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6687\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6635\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6576\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6519\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6453\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6377\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6294\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6198\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6089\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5982\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5874\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5756\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5628\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5481\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5324\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5154\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4974\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4778\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4574\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4353\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4120\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3881\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3653\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3409\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3151\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2898\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2662\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2436\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2211\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1982\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1776\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1574\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1390\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1220\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1062\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0912\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0779\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0665\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0569\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0481\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0406\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0341\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0287\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0242\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0203\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0171\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0144\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0123\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0105\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0090\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0078\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0067\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0059\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0052\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0046\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0041\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0036\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0033\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0029\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0027\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0022\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0021\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0019\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0018\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0017\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0016\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0015\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0014\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0012\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0012\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0011\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0010\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9767e-04\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.6146e-04\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.2846e-04\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.9835e-04\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.7055e-04\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.4470e-04\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.2137e-04\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.9957e-04\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.7904e-04\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.6063e-04\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4308e-04\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2673e-04\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1081e-04\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9595e-04\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.8224e-04\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6921e-04\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5666e-04\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.4455e-04\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.3317e-04\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.2230e-04\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.1196e-04\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0208e-04\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9246e-04\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.8310e-04\n",
      "Epoch 103/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7401e-04\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6524e-04\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5692e-04\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.4888e-04\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4114e-04\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.3362e-04\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.2629e-04\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.1941e-04\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1266e-04\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.0587e-04\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.9921e-04\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.9280e-04\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.8644e-04\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.8036e-04\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7448e-04\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6871e-04\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.6311e-04\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.5749e-04\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5199e-04\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.4658e-04\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.4147e-04\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.3638e-04\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3131e-04\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2638e-04\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2150e-04\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.1668e-04\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.1207e-04\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0735e-04\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0270e-04\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9825e-04\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9390e-04\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8968e-04\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8527e-04\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8102e-04\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7693e-04\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7285e-04\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6879e-04\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6487e-04\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6096e-04\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5705e-04\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.5334e-04\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4966e-04\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4597e-04\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.4231e-04\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.3875e-04\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.3512e-04\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.3178e-04\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2836e-04\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2489e-04\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.2157e-04\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.1838e-04\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.1513e-04\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.1192e-04\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0876e-04\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.0565e-04\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.0262e-04\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9958e-04\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.9653e-04\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.9361e-04\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.9074e-04\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8787e-04\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.8507e-04\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.8224e-04\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7950e-04\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.7682e-04\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7416e-04\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.7157e-04\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6894e-04\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6631e-04\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6385e-04\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.6133e-04\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5886e-04\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.5643e-04\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5404e-04\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5166e-04\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4931e-04\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4698e-04\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4471e-04\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.4247e-04\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4025e-04\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3805e-04\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3588e-04\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3375e-04\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3164e-04\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2954e-04\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2750e-04\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.2545e-04\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2343e-04\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2149e-04\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1952e-04\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1758e-04\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1571e-04\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1383e-04\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1194e-04\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1014e-04\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0830e-04\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0653e-04\n",
      "Epoch 200/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0477e-04\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.0302e-04\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.0128e-04\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.9961e-04\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9790e-04\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9625e-04\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9460e-04\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9297e-04\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9143e-04\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8982e-04\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.8825e-04\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8672e-04\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8519e-04\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8367e-04\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8217e-04\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8069e-04\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7925e-04\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7782e-04\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7639e-04\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7498e-04\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7361e-04\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7224e-04\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7089e-04\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6955e-04\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6824e-04\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6693e-04\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6563e-04\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6433e-04\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6314e-04\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6186e-04\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6061e-04\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5941e-04\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5822e-04\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5703e-04\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5584e-04\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5465e-04\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5347e-04\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5234e-04\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5123e-04\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5009e-04\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4898e-04\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4789e-04\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4672e-04\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4551e-04\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4426e-04\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4303e-04\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4180e-04\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4055e-04\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3930e-04\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3808e-04\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3686e-04\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3565e-04\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3446e-04\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3327e-04\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.3212e-04\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3097e-04\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2985e-04\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2875e-04\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2766e-04\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2658e-04\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2552e-04\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2448e-04\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2346e-04\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2246e-04\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2147e-04\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2051e-04\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1955e-04\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1861e-04\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1769e-04\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1678e-04\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1590e-04\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1502e-04\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1415e-04\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1329e-04\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1247e-04\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1163e-04\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1082e-04\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1002e-04\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0922e-04\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0847e-04\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0769e-04\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0694e-04\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0621e-04\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0547e-04\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0474e-04\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0403e-04\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0331e-04\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0262e-04\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0194e-04\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0125e-04\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0057e-04\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.9913e-05\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9261e-05\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.8614e-05\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7980e-05\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.7353e-05\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.6720e-05\n",
      "Epoch 297/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 9.6107e-05\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.5500e-05\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.4896e-05\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.4309e-05\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.3713e-05\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.3133e-05\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.2558e-05\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.1992e-05\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.1428e-05\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.0875e-05\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.0326e-05\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.9779e-05\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.9236e-05\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.8716e-05\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.8176e-05\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7652e-05\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.7137e-05\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.6627e-05\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.6119e-05\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.5616e-05\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.5122e-05\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4629e-05\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4137e-05\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.3664e-05\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.3181e-05\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.2710e-05\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2237e-05\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.1773e-05\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.1311e-05\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.0855e-05\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.0405e-05\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.9960e-05\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.9517e-05\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9077e-05\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8641e-05\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.8209e-05\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.7791e-05\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7361e-05\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.6946e-05\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.6536e-05\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.6118e-05\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5708e-05\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.5308e-05\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4906e-05\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4503e-05\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.4110e-05\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3718e-05\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3329e-05\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2944e-05\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2562e-05\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2183e-05\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1817e-05\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1438e-05\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1072e-05\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0707e-05\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0342e-05\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.9981e-05\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9623e-05\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9272e-05\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.8921e-05\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8573e-05\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.8225e-05\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.7882e-05\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7538e-05\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.7214e-05\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6866e-05\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6538e-05\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.6212e-05\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.5887e-05\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.5562e-05\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.5237e-05\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4914e-05\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.4594e-05\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.4285e-05\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3975e-05\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.3658e-05\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.3351e-05\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.3048e-05\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.2745e-05\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.2446e-05\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.2147e-05\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.1847e-05\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.1550e-05\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.1255e-05\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0977e-05\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0681e-05\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0396e-05\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0117e-05\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9838e-05\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9560e-05\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.9284e-05\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9008e-05\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.8731e-05\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.8455e-05\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.8183e-05\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.7913e-05\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7660e-05\n",
      "Epoch 394/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7390e-05\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.7118e-05\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.6860e-05\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.6602e-05\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6345e-05\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.6089e-05\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5834e-05\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.5590e-05\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5340e-05\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.5085e-05\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4840e-05\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4595e-05\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4352e-05\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4109e-05\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.3870e-05\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.3633e-05\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.3396e-05\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.3160e-05\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2927e-05\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.2695e-05\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2465e-05\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.2238e-05\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.2009e-05\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1784e-05\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.1560e-05\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 5.1338e-05\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.1117e-05\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.0898e-05\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0679e-05\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0461e-05\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.0246e-05\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.0032e-05\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.9819e-05\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.9609e-05\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.9398e-05\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.9190e-05\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8981e-05\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8780e-05\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8572e-05\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.8372e-05\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.8171e-05\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.7971e-05\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.7772e-05\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7574e-05\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.7376e-05\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.7179e-05\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6983e-05\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.6793e-05\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.6596e-05\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.6406e-05\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.6216e-05\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6026e-05\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.5843e-05\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.5654e-05\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.5471e-05\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.5288e-05\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.5106e-05\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.4924e-05\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.4743e-05\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.4563e-05\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.4383e-05\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.4206e-05\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.4028e-05\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.3853e-05\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3680e-05\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.3508e-05\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.3336e-05\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.3165e-05\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2994e-05\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2823e-05\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.2656e-05\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.2490e-05\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.2324e-05\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.2159e-05\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1997e-05\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.1835e-05\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.1673e-05\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.1511e-05\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.1350e-05\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.1190e-05\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.1030e-05\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0874e-05\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.0716e-05\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0561e-05\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0407e-05\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.0254e-05\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.0102e-05\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.9948e-05\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.9796e-05\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9644e-05\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9500e-05\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.9347e-05\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9200e-05\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9055e-05\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8909e-05\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8764e-05\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8622e-05\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8477e-05\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8332e-05\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8189e-05\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8047e-05\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.7907e-05\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.7767e-05\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7628e-05\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7490e-05\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7353e-05\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7216e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(input_data, output_data, epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x177d50e29d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(10,10))\n",
    "plt.plot(history.history['loss'], linewidth=3, label='Train loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[0., 0.], [0., 1.], [1., 0.], [1., 1.]], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo II: Regla XOR en Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense( inputs , weights, bias):\n",
    "    layer = tf.matmul(inputs, weights) + bias\n",
    "    return tf.nn.relu(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight( shape , name ):\n",
    "    return tf.Variable(tf.random.truncated_normal(shape,stddev=0.1), name=name, trainable=True, dtype=tf.float32)\n",
    "\n",
    "shapes = [[ 2 , 10 ] ,             #0\n",
    "          [ 10 , 10 ] ,            #1\n",
    "          [ 10 , 10 ] ,            #2\n",
    "          [ 10 , output_classes ]] #3\n",
    "\n",
    "weights = []\n",
    "bias = []\n",
    "for i in range( len( shapes ) ):\n",
    "    weights.append( get_weight( shapes[ i ] , 'weight{}'.format( i ) ) )\n",
    "\n",
    "for i in range( len( shapes ) ):\n",
    "    bias.append( get_weight( [1,shapes[i][-1]], 'bias{}'.format( i ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_variables():\n",
    "    return weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'weight0:0' shape=(2, 10) dtype=float32, numpy=\n",
      "array([[-0.11553383, -0.13362448,  0.04237421, -0.05113244,  0.08354783,\n",
      "        -0.0354839 ,  0.01864559, -0.01574503, -0.03290727, -0.01646124],\n",
      "       [-0.07693469, -0.06951549, -0.14932626,  0.18388323,  0.08734736,\n",
      "         0.13595158, -0.05184274,  0.04685344,  0.05260237, -0.10850147]],\n",
      "      dtype=float32)>, <tf.Variable 'weight1:0' shape=(10, 10) dtype=float32, numpy=\n",
      "array([[ 0.10221205, -0.00575391,  0.05367698, -0.00621092, -0.01781065,\n",
      "        -0.16033751, -0.07267689, -0.04199148, -0.08323793,  0.00900982],\n",
      "       [-0.15017243,  0.06971965,  0.01745071, -0.09449199,  0.02638444,\n",
      "        -0.15355551,  0.13269298,  0.03559313, -0.01568986,  0.00149638],\n",
      "       [-0.0913851 , -0.0449467 , -0.06474373,  0.01387805,  0.16869977,\n",
      "        -0.16357982, -0.0198369 , -0.09070364,  0.15160443,  0.09472664],\n",
      "       [ 0.05649941,  0.14977847, -0.05917475, -0.06123916, -0.07152217,\n",
      "        -0.05112651,  0.07203563,  0.0800701 , -0.07085876,  0.11374283],\n",
      "       [ 0.13568509,  0.09318537, -0.05957851, -0.13019376,  0.03621731,\n",
      "         0.18555348,  0.11588683,  0.0184918 , -0.11577489, -0.03700609],\n",
      "       [ 0.030292  , -0.09950966,  0.02113381,  0.11173745,  0.08386534,\n",
      "        -0.053724  ,  0.07867636, -0.03048979,  0.09471589, -0.03770799],\n",
      "       [ 0.0898855 ,  0.00265178, -0.07032679,  0.06928153, -0.04581012,\n",
      "         0.07033923, -0.02298453,  0.09572665, -0.01468714,  0.03146284],\n",
      "       [ 0.04505116, -0.00092103,  0.00857362,  0.014515  ,  0.04016949,\n",
      "         0.12882943, -0.01882433, -0.12509465,  0.0848101 , -0.13187556],\n",
      "       [-0.01452901,  0.0143663 ,  0.09353698, -0.03641182,  0.08586349,\n",
      "        -0.09227883,  0.06442934, -0.03844469, -0.05166478, -0.10471264],\n",
      "       [-0.04984929,  0.06241598, -0.17569064, -0.10553565, -0.11495055,\n",
      "         0.13734345,  0.08696978,  0.13212071,  0.02158817,  0.0476873 ]],\n",
      "      dtype=float32)>, <tf.Variable 'weight2:0' shape=(10, 10) dtype=float32, numpy=\n",
      "array([[-1.05483077e-01, -8.88377652e-02, -1.86261266e-01,\n",
      "         5.15439622e-02, -5.71208410e-02,  1.38664156e-01,\n",
      "         7.50726834e-02,  5.38875535e-02,  3.54912877e-02,\n",
      "        -1.29148558e-01],\n",
      "       [-3.13332528e-02, -1.06811903e-01,  1.04760684e-01,\n",
      "         4.58550192e-02, -1.85605586e-02,  1.28523707e-01,\n",
      "        -2.60761958e-02, -1.69738770e-01,  2.58955602e-02,\n",
      "         1.15306117e-01],\n",
      "       [ 9.26462468e-03,  2.49881875e-02,  2.84927674e-02,\n",
      "        -1.56601101e-01,  5.09175956e-02, -8.59545842e-02,\n",
      "         1.03905752e-01, -1.97576713e-02,  1.50528416e-01,\n",
      "        -8.67022797e-02],\n",
      "       [ 7.40236491e-02, -1.62443057e-01, -1.03094235e-01,\n",
      "         1.62842914e-01, -2.89296098e-02, -1.62282362e-04,\n",
      "        -2.76044160e-02,  9.13947076e-02,  5.78004606e-02,\n",
      "         2.13500205e-02],\n",
      "       [ 7.53274187e-02,  3.18902023e-02,  4.86422534e-04,\n",
      "         5.16871922e-02,  2.53808741e-02,  7.48343989e-02,\n",
      "        -8.03038105e-02,  1.22835003e-02, -1.75459594e-01,\n",
      "        -8.61377046e-02],\n",
      "       [ 2.65903212e-02, -2.35001799e-02,  1.32573070e-02,\n",
      "        -7.81615078e-02, -5.18229418e-03, -1.17831230e-01,\n",
      "        -1.52127489e-01,  7.87285790e-02, -1.38252079e-02,\n",
      "        -3.63586992e-02],\n",
      "       [-9.59815010e-02,  8.48420188e-02, -1.28308013e-01,\n",
      "        -2.73634326e-02, -3.04581947e-03,  1.33025681e-03,\n",
      "        -1.01753930e-02,  7.98687432e-03, -5.20218387e-02,\n",
      "        -3.50823514e-02],\n",
      "       [ 4.19611000e-02, -9.89975706e-02,  1.90354884e-02,\n",
      "        -2.38087866e-02, -1.99618395e-02, -1.81169366e-03,\n",
      "         3.34828682e-02, -9.03624445e-02,  7.60394260e-02,\n",
      "         2.31852811e-02],\n",
      "       [-2.18859799e-02,  9.29846521e-03, -4.62441556e-02,\n",
      "        -9.02189836e-02, -9.65424851e-02,  5.74346967e-02,\n",
      "         3.79393212e-02,  1.86301574e-01, -6.47253916e-02,\n",
      "        -6.98540965e-03],\n",
      "       [ 6.94528148e-02, -4.06981371e-02,  1.23273157e-01,\n",
      "        -4.31455448e-02,  2.91885920e-02, -1.34066254e-01,\n",
      "        -6.75945207e-02,  1.66314855e-01,  1.26830816e-01,\n",
      "         5.91251552e-02]], dtype=float32)>, <tf.Variable 'weight3:0' shape=(10, 2) dtype=float32, numpy=\n",
      "array([[ 0.00502814, -0.01989537],\n",
      "       [-0.11362058,  0.02455198],\n",
      "       [-0.02389168,  0.14956187],\n",
      "       [ 0.01449326, -0.03149455],\n",
      "       [ 0.02112177,  0.08126878],\n",
      "       [-0.03764489,  0.01149229],\n",
      "       [-0.06723255, -0.05161269],\n",
      "       [ 0.0086858 ,  0.01664197],\n",
      "       [ 0.01184762,  0.03448761],\n",
      "       [ 0.03337769,  0.00091367]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model( x ) :\n",
    "    x = tf.cast( x , dtype=tf.float32 )\n",
    "    d0 = dense(  x, weights[0], bias[0] )\n",
    "    d1 = dense( d0, weights[1], bias[1] )\n",
    "    d2 = dense( d1, weights[2], bias[2] )\n",
    "    d3 = tf.matmul(d2 , weights[3]) + bias[3]\n",
    "    return tf.nn.softmax( d3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss( pred , target ):\n",
    "    return tf.losses.binary_crossentropy( target , pred )\n",
    "\n",
    "optimizer = tf.optimizers.Adam( learning_rate )\n",
    "\n",
    "def train_step( model, inputs , outputs ):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss( model( inputs ), outputs)\n",
    "    grads = tape.gradient( current_loss , trainable_variables() )\n",
    "    optimizer.apply_gradients( zip( grads , trainable_variables() ) )\n",
    "    print( tf.reduce_mean( current_loss ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.697839, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69605523, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6947074, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6937579, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6931734, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6928915, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69286025, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6929457, shape=(), dtype=float32)\n",
      "tf.Tensor(0.692998, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69294304, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6925349, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69195515, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6912051, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69026476, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6893089, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68855965, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68701077, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6848422, shape=(), dtype=float32)\n",
      "tf.Tensor(0.68270177, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67997235, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6765075, shape=(), dtype=float32)\n",
      "tf.Tensor(0.67204034, shape=(), dtype=float32)\n",
      "tf.Tensor(0.66645014, shape=(), dtype=float32)\n",
      "tf.Tensor(0.660226, shape=(), dtype=float32)\n",
      "tf.Tensor(0.65330327, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6445138, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6344903, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6241107, shape=(), dtype=float32)\n",
      "tf.Tensor(0.6117632, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5999609, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5851889, shape=(), dtype=float32)\n",
      "tf.Tensor(0.568984, shape=(), dtype=float32)\n",
      "tf.Tensor(0.55251014, shape=(), dtype=float32)\n",
      "tf.Tensor(0.5340123, shape=(), dtype=float32)\n",
      "tf.Tensor(0.51418924, shape=(), dtype=float32)\n",
      "tf.Tensor(0.49350047, shape=(), dtype=float32)\n",
      "tf.Tensor(0.4728117, shape=(), dtype=float32)\n",
      "tf.Tensor(0.45144108, shape=(), dtype=float32)\n",
      "tf.Tensor(0.42927992, shape=(), dtype=float32)\n",
      "tf.Tensor(0.40569147, shape=(), dtype=float32)\n",
      "tf.Tensor(0.38009942, shape=(), dtype=float32)\n",
      "tf.Tensor(0.35285166, shape=(), dtype=float32)\n",
      "tf.Tensor(0.32500267, shape=(), dtype=float32)\n",
      "tf.Tensor(0.29958287, shape=(), dtype=float32)\n",
      "tf.Tensor(0.27013996, shape=(), dtype=float32)\n",
      "tf.Tensor(0.24302875, shape=(), dtype=float32)\n",
      "tf.Tensor(0.21754831, shape=(), dtype=float32)\n",
      "tf.Tensor(0.19273616, shape=(), dtype=float32)\n",
      "tf.Tensor(0.17024803, shape=(), dtype=float32)\n",
      "tf.Tensor(0.15011853, shape=(), dtype=float32)\n",
      "tf.Tensor(0.13172287, shape=(), dtype=float32)\n",
      "tf.Tensor(0.11444375, shape=(), dtype=float32)\n",
      "tf.Tensor(0.098311365, shape=(), dtype=float32)\n",
      "tf.Tensor(0.08422929, shape=(), dtype=float32)\n",
      "tf.Tensor(0.07267954, shape=(), dtype=float32)\n",
      "tf.Tensor(0.06330289, shape=(), dtype=float32)\n",
      "tf.Tensor(0.055207707, shape=(), dtype=float32)\n",
      "tf.Tensor(0.048793163, shape=(), dtype=float32)\n",
      "tf.Tensor(0.043540545, shape=(), dtype=float32)\n",
      "tf.Tensor(0.038624518, shape=(), dtype=float32)\n",
      "tf.Tensor(0.03447066, shape=(), dtype=float32)\n",
      "tf.Tensor(0.030838203, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0276151, shape=(), dtype=float32)\n",
      "tf.Tensor(0.024755668, shape=(), dtype=float32)\n",
      "tf.Tensor(0.022222012, shape=(), dtype=float32)\n",
      "tf.Tensor(0.019983325, shape=(), dtype=float32)\n",
      "tf.Tensor(0.01800271, shape=(), dtype=float32)\n",
      "tf.Tensor(0.016251264, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0147033855, shape=(), dtype=float32)\n",
      "tf.Tensor(0.013335835, shape=(), dtype=float32)\n",
      "tf.Tensor(0.012127613, shape=(), dtype=float32)\n",
      "tf.Tensor(0.011059904, shape=(), dtype=float32)\n",
      "tf.Tensor(0.010116126, shape=(), dtype=float32)\n",
      "tf.Tensor(0.009283593, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0085463775, shape=(), dtype=float32)\n",
      "tf.Tensor(0.007892587, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0073118056, shape=(), dtype=float32)\n",
      "tf.Tensor(0.006795164, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0063360217, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0059265303, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0055606253, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0052317902, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0049353554, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0046673184, shape=(), dtype=float32)\n",
      "tf.Tensor(0.004424272, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0042038565, shape=(), dtype=float32)\n",
      "tf.Tensor(0.004002955, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0038193534, shape=(), dtype=float32)\n",
      "tf.Tensor(0.003651145, shape=(), dtype=float32)\n",
      "tf.Tensor(0.003496674, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0033545434, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00322351, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0031024604, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00299047, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0028866471, shape=(), dtype=float32)\n",
      "tf.Tensor(0.002790221, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0027005048, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0026168562, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0025387178, shape=(), dtype=float32)\n",
      "tf.Tensor(0.002465637, shape=(), dtype=float32)\n",
      "tf.Tensor(0.002397094, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0023327575, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0022721759, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0022150858, shape=(), dtype=float32)\n",
      "tf.Tensor(0.002161171, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0021114745, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0020646746, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0020200962, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0019775815, shape=(), dtype=float32)\n",
      "tf.Tensor(0.001936995, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0018981565, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0018609979, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0018253098, shape=(), dtype=float32)\n",
      "tf.Tensor(0.001791069, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0017581331, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0017264341, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0016958899, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0016666426, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0016392828, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0016126717, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0015867949, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0015618016, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0015384331, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0015147494, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0014908784, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0014682504, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0014468431, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0014263206, shape=(), dtype=float32)\n",
      "tf.Tensor(0.001406293, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0013866854, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0013675056, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0013492241, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0013313101, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0013137256, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0012964784, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0012795458, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0012629207, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0012466173, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0012305838, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0012151939, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0012006194, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0011858499, shape=(), dtype=float32)\n",
      "tf.Tensor(0.001171035, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0011568412, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0011428122, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0011292698, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0011159971, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0011031067, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010903586, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010777757, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010653207, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010532769, shape=(), dtype=float32)\n",
      "tf.Tensor(0.001041308, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010294517, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010180738, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0010070176, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000996051, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0009851892, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00097441726, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0009639221, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000953644, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0009434482, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0009334766, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00092382665, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0009142741, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00090470683, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0008952742, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00088608847, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0008770373, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00086819544, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0008594806, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0008508779, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00084232766, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0008339569, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0008258329, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00081762666, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00080960745, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.00080179004, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0007940698, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00078644673, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00077896577, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00077149237, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0007642355, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00075700093, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00074999814, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0007429881, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000736038, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00072914787, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0007226239, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0007158606, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0007093138, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00070285675, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000696497, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00069031666, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00068412104, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006780526, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006719919, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006660209, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006601843, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006544895, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00064878725, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006431447, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006375843, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006320988, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00062667317, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006214492, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00061614317, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006108145, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00060570246, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0006007322, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00059576205, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005908069, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005859562, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005811133, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00057632255, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00057156937, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005669132, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005623764, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00055769767, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005532579, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000548848, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005444382, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00054014777, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00053583505, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00053166423, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00052747846, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00052332995, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00051925617, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00051522726, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005112432, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00050729635, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0005033943, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000499552, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00049575453, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00049199443, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0004883164, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00048460107, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00048103507, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00047761083, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0004740148, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0004704636, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00046705428, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00046365985, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00046028045, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00045693092, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00045356658, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00045026193, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0004472035, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00044393615, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00044069104, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00043762504, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00043455174, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00043147095, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0004284425, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00042547376, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00042249763, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00041951396, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00041653783, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00041367355, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0004108168, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00040795264, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00040520032, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00040241817, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003997555, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00039699575, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003943554, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00039178965, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00038909697, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003865163, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00038395057, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00038140724, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00037890123, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00037642507, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00037392657, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00037149523, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00036909373, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00036672945, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003643652, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000362001, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003597039, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00035735473, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00035503533, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00035279055, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00035056067, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00034827855, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00034611576, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003439605, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00034177542, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00033963512, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003375023, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00033541428, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003333187, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003312231, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00032919465, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0003271663, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00032516025, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00032316917, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00032123778, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00031929885, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00031735253, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00031546582, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00031356423, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00031169254, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00030985058, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00030801614, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00030618923, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00030437723, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00030257262, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00030080532, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002990381, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00029728573, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00029557064, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00029387054, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00029216293, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00029044793, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00028878512, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00028709997, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00028553407, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00028386377, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002822531, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00028065746, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002791065, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00027752572, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00027596732, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000274409, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002728581, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00027132954, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002698085, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00026828743, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00026678128, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00026537204, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00026389572, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00026245666, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002609878, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002595637, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00025813218, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002567379, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00025537342, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002539643, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002526073, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00025127272, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002499083, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024860352, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024726143, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002459492, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024464447, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024333972, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024207972, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00024077497, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.00023951495, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00023826987, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00023701733, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00023580207, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00023454953, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002333194, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00023214142, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00023092616, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022975566, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022859259, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022741464, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022627397, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022511094, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022397024, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022285197, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022170386, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00022060791, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021948216, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021838627, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021730526, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021622427, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002151358, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021409952, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021304833, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021199716, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021094602, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020993958, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020889587, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020782984, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020680105, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002058095, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002047882, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020379668, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020284246, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00020186587, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0002008967, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019992013, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019896592, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019803406, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019709476, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019614055, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019521615, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019430666, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019335993, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019246536, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019156335, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00019066878, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018978168, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001888946, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018802985, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001871502, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000186278, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001854133, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018455602, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001837286, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018287876, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00018204383, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001812164, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001803815, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017956897, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017876389, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017796629, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017713885, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017630395, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001755287, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001747609, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017395584, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017316568, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017242024, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017163756, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017087723, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00017010196, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016936401, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016860367, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016787316, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001671352, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001664047, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016568908, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016495114, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016425046, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016351248, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016280435, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016211113, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001614328, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001607172, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00016002398, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015934567, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015865244, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015795924, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015726603, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015662497, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015597646, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015531309, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015464223, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015400119, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001533527, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001527042, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015204826, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001514296, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00015080349, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000150155, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014953632, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014893257, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014829152, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014769525, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014707657, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014646535, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014587653, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014528024, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014468393, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014408764, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014352116, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014291742, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001423211, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014176953, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014120305, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014062913, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00014004775, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013948129, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013893716, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013840797, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013784149, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013726756, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001367309, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013617188, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013565757, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013511347, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013458428, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013402526, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013351098, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013298179, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013247496, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013193085, shape=(), dtype=float32)\n",
      "tf.Tensor(0.000131424, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013090973, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00013041035, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012990352, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012938179, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012888241, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012839795, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012788366, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012739174, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012692217, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012643026, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012593833, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012546878, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012497685, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0001244924, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012405266, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012357564, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00012311354, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for e in range( epochs ):\n",
    "    train_step( model, input_data , output_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'weight0:0' shape=(2, 10) dtype=float32, numpy=\n",
      "array([[-0.6050465 , -0.13362448,  0.04237421, -0.5212773 , -0.03879997,\n",
      "         0.23868611,  0.01864559,  0.16606621, -0.47140703, -0.01646124],\n",
      "       [-0.60211945, -0.06951549, -0.14932626,  0.5212837 , -0.03130277,\n",
      "         0.6492672 , -0.05184274,  0.5279299 ,  0.47784492, -0.10850147]],\n",
      "      dtype=float32)>, <tf.Variable 'weight1:0' shape=(10, 10) dtype=float32, numpy=\n",
      "array([[ 1.0283931 , -0.00575391,  0.00280519,  0.9210366 , -0.01781065,\n",
      "        -0.16033751, -0.81981105, -0.04199148,  0.83066416,  0.00900982],\n",
      "       [-0.04958231,  0.06971965,  0.01745071,  0.01075344,  0.02638444,\n",
      "        -0.15355551,  0.22960639,  0.03559313,  0.09534978,  0.00149638],\n",
      "       [-0.0913851 , -0.0449467 , -0.06474373,  0.01387805,  0.16869977,\n",
      "        -0.16357982, -0.0198369 , -0.09070364,  0.15160443,  0.09472664],\n",
      "       [-0.415608  ,  0.09929713, -0.05917475, -0.5963638 , -0.07152217,\n",
      "        -0.05112651,  0.90396106,  0.0800701 , -0.6202613 ,  0.11374283],\n",
      "       [ 0.21251833,  0.09318537, -0.05957851, -0.03898301,  0.03621731,\n",
      "         0.18555348,  0.17453292,  0.0184918 , -0.04826319, -0.03700609],\n",
      "       [ 0.59568167, -0.14283901,  0.02113381,  0.7156059 ,  0.01419575,\n",
      "        -0.053724  , -0.196481  , -0.03048979,  0.72193706, -0.03770799],\n",
      "       [ 0.0898855 ,  0.00265178, -0.07032679,  0.06928153, -0.04581012,\n",
      "         0.07033923, -0.02298453,  0.09572665, -0.01468714,  0.03146284],\n",
      "       [ 0.58125186, -0.04023975, -0.04151948,  0.5315611 , -0.02947129,\n",
      "         0.12882943, -0.14180066, -0.12509465,  0.61864233, -0.13187556],\n",
      "       [-0.50340074, -0.03435638,  0.09353698, -0.5707757 ,  0.08586349,\n",
      "        -0.09227883,  0.9090568 , -0.03844469, -0.60113776, -0.10471264],\n",
      "       [-0.04984929,  0.06241598, -0.17569064, -0.10553565, -0.11495055,\n",
      "         0.13734345,  0.08696978,  0.13212071,  0.02158817,  0.0476873 ]],\n",
      "      dtype=float32)>, <tf.Variable 'weight2:0' shape=(10, 10) dtype=float32, numpy=\n",
      "array([[ 7.4649745e-01, -7.9609931e-01, -8.3788317e-01,  6.6785598e-01,\n",
      "        -5.7120841e-02,  9.0354651e-01,  2.0315448e-02,  8.5004318e-01,\n",
      "         8.4974921e-01,  7.3274750e-01],\n",
      "       [-3.1333253e-02, -8.7474063e-02,  1.2424702e-01,  4.5855019e-02,\n",
      "        -1.8560559e-02,  1.2852371e-01, -2.6076196e-02, -1.6973877e-01,\n",
      "         2.5895560e-02,  1.1530612e-01],\n",
      "       [ 5.6313451e-02, -1.1954204e-02, -1.4236843e-02, -1.5660110e-01,\n",
      "         5.0917596e-02, -4.2932346e-02,  1.0390575e-01,  2.6563283e-02,\n",
      "         1.9547483e-01, -3.9547030e-02],\n",
      "       [ 9.0632921e-01, -5.7279658e-01, -4.8042196e-01,  7.8137964e-01,\n",
      "        -2.8929610e-02,  6.9683653e-01, -8.7058842e-02,  8.4632313e-01,\n",
      "         8.3467185e-01,  8.6828977e-01],\n",
      "       [ 1.4341548e-01,  3.1890202e-02,  4.8642253e-04,  5.1687192e-02,\n",
      "         2.5380874e-02,  1.4282528e-01, -8.0303811e-02,  8.0713362e-02,\n",
      "        -1.0756707e-01, -1.8170500e-02],\n",
      "       [ 2.6590321e-02, -2.3500180e-02,  1.3257307e-02, -7.8161508e-02,\n",
      "        -5.1822942e-03, -1.1783123e-01, -1.5212749e-01,  7.8728579e-02,\n",
      "        -1.3825208e-02, -3.6358699e-02],\n",
      "       [-6.6540247e-01,  1.1763396e+00,  9.4169807e-01, -2.9627287e-01,\n",
      "        -3.0458195e-03, -5.9449649e-01, -6.8964221e-02, -4.9971077e-01,\n",
      "        -6.8966740e-01, -5.9003097e-01],\n",
      "       [ 4.1961100e-02, -9.8997571e-02,  1.9035488e-02, -2.3808787e-02,\n",
      "        -1.9961840e-02, -1.8116937e-03,  3.3482868e-02, -9.0362445e-02,\n",
      "         7.6039426e-02,  2.3185281e-02],\n",
      "       [ 8.0611926e-01, -3.8191041e-01, -4.2120382e-01,  5.3504735e-01,\n",
      "        -9.6542485e-02,  7.6840776e-01, -2.0484436e-02,  9.4639981e-01,\n",
      "         7.1615481e-01,  8.3347297e-01],\n",
      "       [ 6.9452815e-02, -4.0698137e-02,  1.2327316e-01, -4.3145545e-02,\n",
      "         2.9188592e-02, -1.3406625e-01, -6.7594521e-02,  1.6631486e-01,\n",
      "         1.2683082e-01,  5.9125155e-02]], dtype=float32)>, <tf.Variable 'weight3:0' shape=(10, 2) dtype=float32, numpy=\n",
      "array([[ 0.70387965, -0.7187475 ],\n",
      "       [-1.0443438 ,  0.95527554],\n",
      "       [-0.93677706,  1.0624479 ],\n",
      "       [ 0.5898916 , -0.6068938 ],\n",
      "       [ 0.02112177,  0.08126878],\n",
      "       [ 0.6908892 , -0.71704185],\n",
      "       [-0.00741446, -0.11143075],\n",
      "       [ 0.8044696 , -0.7791416 ],\n",
      "       [ 0.7043455 , -0.6580103 ],\n",
      "       [ 0.7108608 , -0.67656994]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[9.9995112e-01, 4.8846417e-05],\n",
       "       [1.6336009e-05, 9.9998367e-01],\n",
       "       [4.1942793e-04, 9.9958056e-01],\n",
       "       [9.9999368e-01, 6.3587195e-06]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
